{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install necessary packages, namely pandas and prophet if you do not have already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('GNPDataset.csv', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is good, but need to drop last two columns and then reformat csv with date in one column and the visitor number in the second column to feed prophet properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glacier_national_park_visits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-01-01</th>\n",
       "      <td>6,357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-02-01</th>\n",
       "      <td>3,480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-03-01</th>\n",
       "      <td>11,790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-01</th>\n",
       "      <td>15,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-01</th>\n",
       "      <td>65,923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-01</th>\n",
       "      <td>670,628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01</th>\n",
       "      <td>533,388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01</th>\n",
       "      <td>149,564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-01</th>\n",
       "      <td>26,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>17,629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           glacier_national_park_visits\n",
       "date                                   \n",
       "1979-01-01                        6,357\n",
       "1979-02-01                        3,480\n",
       "1979-03-01                       11,790\n",
       "1979-04-01                       15,000\n",
       "1979-05-01                       65,923\n",
       "...                                 ...\n",
       "2021-08-01                      670,628\n",
       "2021-09-01                      533,388\n",
       "2021-10-01                      149,564\n",
       "2021-11-01                       26,300\n",
       "2021-12-01                       17,629\n",
       "\n",
       "[516 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set 'Year' as the index, so that I can stack the dataframe, ie reduce the dimensions so that I can merge the dataframes\n",
    "df = df.set_index('Year')\n",
    "# drop 'Textbox4' and 'AnnualTotal' column. This is a yearly % change and yearly total column for the dataset\n",
    "df = df.drop(columns=['Textbox4','AnnualTotal'])\n",
    "# now I'm going to stack, meaning move the columns headers under the index, to reduce the dimensionality of the dataframe\n",
    "df = df.stack(level=0)\n",
    "# stacking produces a series when I'm done, and it will need to be converted back into a DF\n",
    "df = df.to_frame()\n",
    "# now add a title to the DF's only column\n",
    "df.columns = ['glacier_national_park_visits']\n",
    "# reset the index to seperate the current multi-index into distinct year and month columns\n",
    "df = df.reset_index(drop=False)\n",
    "# create a composite date column\n",
    "df['date'] = df.Year.astype(str) + \"-\" + df.level_1\n",
    "# convert the date column to datetime object\n",
    "df.date = pd.to_datetime(df.date)\n",
    "# set the date as the index and sort index\n",
    "df = df.set_index('date').sort_index()\n",
    "# drop Year and level_1 columns that are no longer needed\n",
    "df = df.drop(columns=['Year', 'level_1'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\divergence\\OneDrive - DIVERGENCE ONE\\Documents\\GitHub\\2022-07-DSI-WDX\\douglas481\\ML and Python Capstone\\IndexedData.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IndexedData.csv', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>6,357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979-02-01</td>\n",
       "      <td>3,480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979-03-01</td>\n",
       "      <td>11,790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979-04-01</td>\n",
       "      <td>15,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979-05-01</td>\n",
       "      <td>65,923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>670,628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>533,388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>149,564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>26,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>17,629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ds        y\n",
       "0    1979-01-01    6,357\n",
       "1    1979-02-01    3,480\n",
       "2    1979-03-01   11,790\n",
       "3    1979-04-01   15,000\n",
       "4    1979-05-01   65,923\n",
       "..          ...      ...\n",
       "511  2021-08-01  670,628\n",
       "512  2021-09-01  533,388\n",
       "513  2021-10-01  149,564\n",
       "514  2021-11-01   26,300\n",
       "515  2021-12-01   17,629\n",
       "\n",
       "[516 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.columns = ['ds', 'y']\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ds    object\n",
       "y     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has been cleaned and formatted to be fed to Prophet, so next we have to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"6,357\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2315\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"6,357\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\divergence\\OneDrive - DIVERGENCE ONE\\Documents\\GitHub\\2022-07-DSI-WDX\\douglas481\\ML and Python Capstone\\Workbook.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/divergence/OneDrive%20-%20DIVERGENCE%20ONE/Documents/GitHub/2022-07-DSI-WDX/douglas481/ML%20and%20Python%20Capstone/Workbook.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m m \u001b[39m=\u001b[39m Prophet(interval_width\u001b[39m=\u001b[39m\u001b[39m0.95\u001b[39m, daily_seasonality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/divergence/OneDrive%20-%20DIVERGENCE%20ONE/Documents/GitHub/2022-07-DSI-WDX/douglas481/ML%20and%20Python%20Capstone/Workbook.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39;49mfit(df)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\prophet\\forecaster.py:1119\u001b[0m, in \u001b[0;36mProphet.fit\u001b[1;34m(self, df, **kwargs)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataframe has less than 2 non-NaN rows.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory_dates \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(pd\u001b[39m.\u001b[39mSeries(df[\u001b[39m'\u001b[39m\u001b[39mds\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique(), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mds\u001b[39m\u001b[39m'\u001b[39m))\u001b[39m.\u001b[39msort_values()\n\u001b[1;32m-> 1119\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup_dataframe(history, initialize_scales\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1120\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory \u001b[39m=\u001b[39m history\n\u001b[0;32m   1121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_auto_seasonalities()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\prophet\\forecaster.py:265\u001b[0m, in \u001b[0;36mProphet.setup_dataframe\u001b[1;34m(self, df, initialize_scales)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39m\"\"\"Prepare dataframe for fitting or predicting.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m \u001b[39mAdds a time index and scales y. Creates auxiliary columns 't', 't_ix',\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39mpd.DataFrame prepared for fitting or predicting.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m df:  \u001b[39m# 'y' will be in training data\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mto_numeric(df[\u001b[39m'\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    266\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misinf(df[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues)\u001b[39m.\u001b[39many():\n\u001b[0;32m    267\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mFound infinity in column y.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\numeric.py:184\u001b[0m, in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    182\u001b[0m coerce_numeric \u001b[39m=\u001b[39m errors \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    183\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m     values, _ \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmaybe_convert_numeric(\n\u001b[0;32m    185\u001b[0m         values, \u001b[39mset\u001b[39;49m(), coerce_numeric\u001b[39m=\u001b[39;49mcoerce_numeric\n\u001b[0;32m    186\u001b[0m     )\n\u001b[0;32m    187\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2357\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"6,357\" at position 0"
     ]
    }
   ],
   "source": [
    "m = Prophet(interval_width=0.95, daily_seasonality=True)\n",
    "model = m.fit(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
