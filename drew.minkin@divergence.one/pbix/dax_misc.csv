Column,DateTableTemplate_9e527bca-553c-41cb-bfd1-1b13c91e13a0,Year = YEAR([Date])
Column,DateTableTemplate_9e527bca-553c-41cb-bfd1-1b13c91e13a0,MonthNo = MONTH([Date])
Column,DateTableTemplate_9e527bca-553c-41cb-bfd1-1b13c91e13a0,"Month = FORMAT([Date], ""MMMM"")"
Column,DateTableTemplate_9e527bca-553c-41cb-bfd1-1b13c91e13a0,QuarterNo = INT(([MonthNo] + 2) / 3)
Column,DateTableTemplate_9e527bca-553c-41cb-bfd1-1b13c91e13a0,"Quarter = ""Qtr "" & [QuarterNo]"
Column,DateTableTemplate_9e527bca-553c-41cb-bfd1-1b13c91e13a0,Day = DAY([Date])
Column,churn_prediction,"Target = if ('churn_prediction'[churn] = 1,""Yes"",""No"")"
Column,jewellery_kmeans_model,"Age (bins) = IF(   ISBLANK('jewellery_kmeans_model'[Age]),   BLANK(),   IF(     'jewellery_kmeans_model'[Age] >= 0,     ROUNDDOWN('jewellery_kmeans_model'[Age] / 3, 0) * 3,     ROUNDUP('jewellery_kmeans_model'[Age] / 3, 0) * 3   ) )"
Column,jewellery_kmeans_model,Dummy = 1
Column,anomaly_knn_model,"Anomaly_Score (bins) = VAR __Count = 20  VAR __Min = MIN('anomaly_knn_model'[Anomaly_Score])  VAR __Max = MAX('anomaly_knn_model'[Anomaly_Score])  VAR __Difference = (__Max - __Min)  VAR __Size = IF(__Difference > 0, __Difference / __Count, 1)  VAR __BinNumber =    IF(     ISBLANK('anomaly_knn_model'[Anomaly_Score]),     BLANK(),     ROUNDDOWN(('anomaly_knn_model'[Anomaly_Score] - __Min) / __Size, 0)   )  RETURN   IF(     ISBLANK('anomaly_knn_model'[Anomaly_Score]),     BLANK(),     __Min + (MIN(__BinNumber, __Count - 1) * __Size)   )"
Column,anomaly_knn_model,"Col10 (bins) = IF(   ISBLANK('anomaly_knn_model'[Col10]),   BLANK(),   IF(     'anomaly_knn_model'[Col10] >= 0,     ROUNDDOWN('anomaly_knn_model'[Col10] / 0.0492752684, 0) * 0.0492752684,     ROUNDUP('anomaly_knn_model'[Col10] / 0.0492752684, 0) * 0.0492752684   ) )"
Column,LocalDateTable_5afb9adf-1dc0-49d6-aedd-b3e605680c87,Year = YEAR([Date])
Column,LocalDateTable_5afb9adf-1dc0-49d6-aedd-b3e605680c87,MonthNo = MONTH([Date])
Column,LocalDateTable_5afb9adf-1dc0-49d6-aedd-b3e605680c87,"Month = FORMAT([Date], ""MMMM"")"
Column,LocalDateTable_5afb9adf-1dc0-49d6-aedd-b3e605680c87,QuarterNo = INT(([MonthNo] + 2) / 3)
Column,LocalDateTable_5afb9adf-1dc0-49d6-aedd-b3e605680c87,"Quarter = ""Qtr "" & [QuarterNo]"
Column,LocalDateTable_5afb9adf-1dc0-49d6-aedd-b3e605680c87,Day = DAY([Date])
Column,employee_xgboost_model_applied,"Predicted = if (employee_xgboost_model_applied[Label] = 0 ,""0P"",""1P"")"
Column,employee_xgboost_model_applied,"Actual = if (employee_xgboost_model_applied[left] = 0 ,""0A"",""1A"")"
Column,employee_xgboost_model_applied,"Outcome = CONCATENATE(         IF(             IF(employee_xgboost_model_applied[Score] >= 0.75,1,0)         = employee_xgboost_model_applied[left]         ,""T""         ,""F"")         ,IF(employee_xgboost_model_applied[Predicted] = ""1P"", ""P"",""N"") )"
Column,cars_reg_price_dt,Error = cars_reg_price_dt[Scored Labels] - cars_reg_price_dt[price]
Column,cars_reg_price_dt,"ErrorType = IF(cars_reg_price_dt[Error] >=0, ""Positive"",""Negative"")"
Column,cars_reg_price_dt,AbsoluteError = Abs(cars_reg_price_dt[Error])
Column,cars_reg_price_dt,"AbsolutePctError =  // (pred - act/act) ABS(DIVIDE(cars_reg_price_dt[price] - cars_reg_price_dt[Scored Labels],cars_reg_price_dt[price]))"
Column,cars_reg_price_dt,"engsize_bin = if(cars_reg_price_dt[enginesize] >150, ""Large"",""Small"")"
Column,cars_reg_price_dt,"curbweight_bin = VAR __Count = 5  VAR __Min = MIN('cars_reg_price_dt'[curbweight])  VAR __Max = MAX('cars_reg_price_dt'[curbweight])  VAR __Difference = (__Max - __Min)  VAR __Size = IF(__Difference > 0, __Difference / __Count, 1)  VAR __BinNumber = INT(('cars_reg_price_dt'[curbweight] - __Min) / __Size)  RETURN   IF(     ISBLANK('cars_reg_price_dt'[curbweight]),     BLANK(),     __Min + (MIN(__BinNumber, __Count - 1) * __Size)   )"
Column,cars_reg_price_dt,"horsepower_bin = VAR __Count = 5  VAR __Min = MIN('cars_reg_price_dt'[horsepower])  VAR __Max = MAX('cars_reg_price_dt'[horsepower])  VAR __Difference = (__Max - __Min)  VAR __Size = IF(__Difference > 0, __Difference / __Count, 1)  VAR __BinNumber = INT(('cars_reg_price_dt'[horsepower] - __Min) / __Size)  RETURN   IF(     ISBLANK('cars_reg_price_dt'[horsepower]),     BLANK(),     __Min + (MIN(__BinNumber, __Count - 1) * __Size)   )"
Column,auto_price_residual,Residiual = auto_price_residual[price] - auto_price_residual[Scored Labels]
Column,auto_price_residual,"Residiual (bins) = VAR __Count = 8  VAR __Min = MIN('auto_price_residual'[Residiual])  VAR __Max = MAX('auto_price_residual'[Residiual])  VAR __Difference = (__Max - __Min)  VAR __Size = IF(__Difference > 0, __Difference / __Count, 1)  VAR __BinNumber =    IF(     ISBLANK('auto_price_residual'[Residiual]),     BLANK(),     ROUNDDOWN(('auto_price_residual'[Residiual] - __Min) / __Size, 0)   )  RETURN   IF(     ISBLANK('auto_price_residual'[Residiual]),     BLANK(),     __Min + (MIN(__BinNumber, __Count - 1) * __Size)   )"
Column,auto_price_residual,"Squared Error = POWER(auto_price_residual[Residiual],2) "
Column,auto_price_residual,"Abs Percentage Error = ABS(auto_price_residual[Residiual]/auto_price_residual[price]) "
Column,auto_price_residual,"Problem Child = IF(auto_price_residual[Residiual] > 1673.70,""Yes"",""No"")"
Column,auto_price_residual,"Percentage Error = DIVIDE(auto_price_residual[Residiual],auto_price_residual[price]) "
Column,auto_price_residual,"bore bin = if(auto_price_residual[bore]>=3.4,""Yes"",""no"")"
Column,auto_price_residual,"curb-weight bin = IF(auto_price_residual[curb-weight] > 2547,""Yes"",""No"")"
Column,Binary Classification Template,"Percentile By Score = IF(   ISBLANK('Binary Classification Template'[Raw Score]),   BLANK(),   IF(     'Binary Classification Template'[Raw Score] >= 0,     ROUNDDOWN('Binary Classification Template'[Raw Score] / 0.008122, 0) * 0.008122,     ROUNDUP('Binary Classification Template'[Raw Score] / 0.008122, 0) * 0.008122   ) )"
Column,Binary Classification Template,Key = 1
Column,Thresholds,Key = 1
Measure,jewellery_kmeans_model,Jewelry Cases = COUNTROWS(jewellery_kmeans_model)
Measure,employee_xgboost_model_applied,Cases = COUNTROWS()
Measure,employee_xgboost_model_applied,Whatif = SUM(employee_xgboost_model_applied[Score])
Measure,employee_xgboost_model_applied,"Precision/PPV =  //TP + PP = TP + (TP+FP)  DIVIDE([True Positive],[Predicted Positive])"
Measure,employee_xgboost_model_applied,"True Positive = CALCULATE([Cases],employee_xgboost_model_applied[Outcome] = ""TP"")"
Measure,employee_xgboost_model_applied,"Predicted Positive = CALCULATE([Cases],OR(employee_xgboost_model_applied[Outcome] = ""TP"" ,employee_xgboost_model_applied[Outcome] = ""FP"" ))"
Measure,employee_xgboost_model_applied,"Actual Positive = CALCULATE([Cases],OR(employee_xgboost_model_applied[Outcome] = ""TP"" ,employee_xgboost_model_applied[Outcome] = ""FN"" ))"
Measure,employee_xgboost_model_applied,"Recall/TPR =  //TP + PP = TP + (TP+FP)  DIVIDE([True Positive],[Actual Positive])"
Measure,cars_reg_price_dt,"MAE (Mean Absolute Error = AVERAGE(cars_reg_price_dt[AbsoluteError]) "
Measure,cars_reg_price_dt,MAPE (Mean Absolute Percentage of Error) = AVERAGE(cars_reg_price_dt[AbsolutePctError])
Measure,Cut Score,"Cut Score Value = SELECTEDVALUE('Cut Score'[Cut Score], 0.2)"
Measure,auto_price_residual,Auto Cases = COUNTROWS()
Measure,auto_price_residual,"RMSE = power(AVERAGE(auto_price_residual[Squared Error]),0.5)"
Measure,auto_price_residual,MAPE = AVERAGE(auto_price_residual[Abs Percentage Error])
Measure,Binary Classification Template,Total Population = COUNTROWS('Binary Classification Template')
Measure,Binary Classification Template,"True Positives # =      SUMX(         'Binary Classification Template'         ,IF(             AND(             'Binary Classification Template'[Raw Score] > 'Cut Score'[Cut Score Value]              ,             'Binary Classification Template'[Actual] = 1             )             ,1             ,0         )     )"
Measure,Binary Classification Template,"True Negatives # =      SUMX(         'Binary Classification Template'         ,IF(             AND(             'Binary Classification Template'[Raw Score] <= 'Cut Score'[Cut Score Value]              ,             'Binary Classification Template'[Actual] = 0             )             ,1             ,0         )     )"
Measure,Binary Classification Template,"False Negatives # =      SUMX(         'Binary Classification Template'         ,IF(             AND(             'Binary Classification Template'[Raw Score] <= 'Cut Score'[Cut Score Value]              ,             'Binary Classification Template'[Actual] = 1             )             ,1             ,0         )     )"
Measure,Binary Classification Template,"False Positives # =      SUMX(         'Binary Classification Template'         ,IF(             AND(             'Binary Classification Template'[Raw Score] > 'Cut Score'[Cut Score Value]              ,             'Binary Classification Template'[Actual] = 0             )             ,1             ,0         )     )"
Measure,Binary Classification Template,"FPR (False Positive Rate) = DIVIDE('Binary Classification Template'[False Positives #],'Binary Classification Template'[Negative Conditions #])"
Measure,Binary Classification Template,Predicted Positive Conditions # = 'Binary Classification Template'[False Positives #] + 'Binary Classification Template'[True Positives #]
Measure,Binary Classification Template,Predicted Negative Conditions # = 'Binary Classification Template'[False Negatives #] + 'Binary Classification Template'[True Negatives #]
Measure,Binary Classification Template,"TPR (True Positive Rate) = DIVIDE('Binary Classification Template'[True Positives #],'Binary Classification Template'[Positive Conditions #])"
Measure,Binary Classification Template,"SPC (Specificity) = ""TNR (True Negative Rate)"""
Measure,Binary Classification Template,"TNR (True Negative Rate) = DIVIDE('Binary Classification Template'[True Negatives #],'Binary Classification Template'[Negative Conditions #])"
Measure,Binary Classification Template,Selectivity = 'Binary Classification Template'[SPC (Specificity)]
Measure,Binary Classification Template,"FNR (False Negative Rate) = DIVIDE('Binary Classification Template'[False Negatives #],'Binary Classification Template'[Positive Conditions #])"
Measure,Binary Classification Template,Negative Conditions # = 'Binary Classification Template'[False Positives #] + 'Binary Classification Template'[True Negatives #]
Measure,Binary Classification Template,Positive Conditions # = 'Binary Classification Template'[False Negatives #] + 'Binary Classification Template'[True Positives #]
Measure,Binary Classification Template,Type I Errors # = 'Binary Classification Template'[False Positives #]
Measure,Binary Classification Template,Type II Errors # = 'Binary Classification Template'[False Negatives #]
Measure,Binary Classification Template,Type I Rate = 'Binary Classification Template'[FPR (False Positive Rate)]
Measure,Binary Classification Template,Type II Rate = 'Binary Classification Template'[FPR (False Positive Rate)]
Measure,Binary Classification Template,Fall-out Rate = 'Binary Classification Template'[FPR (False Positive Rate)]
Measure,Binary Classification Template,Probability of False Alarm = 'Binary Classification Template'[FPR (False Positive Rate)]
Measure,Binary Classification Template,Recall = 'Binary Classification Template'[TPR (True Positive Rate)]
Measure,Binary Classification Template,Probability of Detection = 'Binary Classification Template'[TPR (True Positive Rate)]
Measure,Binary Classification Template,Sensitivity = 'Binary Classification Template'[TPR (True Positive Rate)]
Measure,Binary Classification Template,Power = 'Binary Classification Template'[TPR (True Positive Rate)]
Measure,Binary Classification Template,Miss Rate = 'Binary Classification Template'[FNR (False Negative Rate)]
Measure,Binary Classification Template,"Prevalence = DIVIDE('Binary Classification Template'[Positive Conditions #],'Binary Classification Template'[Total Population])"
Measure,Binary Classification Template,"PPV (Positive Predicted Value) = DIVIDE('Binary Classification Template'[True Positives #],'Binary Classification Template'[Predicted Positive Conditions #])"
Measure,Binary Classification Template,Precision = 'Binary Classification Template'[PPV (Positive Predicted Value)]
Measure,Binary Classification Template,"FOR (False Omission Rate) = DIVIDE('Binary Classification Template'[False Negatives #],'Binary Classification Template'[Predicted Negative Conditions #])"
Measure,Binary Classification Template,"ACC (Accuracy) = DIVIDE('Binary Classification Template'[True Positives #] + 'Binary Classification Template'[True Negatives #],'Binary Classification Template'[Total Population])"
Measure,Binary Classification Template,"FDR (False Dsicovery Rate) = DIVIDE('Binary Classification Template'[False Positives #],'Binary Classification Template'[Predicted Positive Conditions #])"
Measure,Binary Classification Template,"NPV (Negative Predicted Value) = DIVIDE('Binary Classification Template'[True Negatives #],'Binary Classification Template'[Predicted Negative Conditions #])"
Measure,Binary Classification Template,"LR+ (Positive Likelihood Ratio) = DIVIDE('Binary Classification Template'[TPR (True Positive Rate)],'Binary Classification Template'[FPR (False Positive Rate)])"
Measure,Binary Classification Template,"LR- (Negative Likelihood Ratio) = DIVIDE('Binary Classification Template'[FNR (False Negative Rate)],'Binary Classification Template'[TNR (True Negative Rate)])"
Measure,Binary Classification Template,"DOR (Diagnostics Odds Ratio) = DIVIDE('Binary Classification Template'[LR+ (Positive Likelihood Ratio)],'Binary Classification Template'[LR- (Negative Likelihood Ratio)])"
Measure,Binary Classification Template,"F1 Score = 2 * DIVIDE( 'Binary Classification Template'[Precision] * 'Binary Classification Template'[Recall] ,'Binary Classification Template'[Precision] + 'Binary Classification Template'[Recall] )"
Measure,Binary Classification Template,"Cumulative Lift =  //Actual positive density above score percentile  DIVIDE (     DIVIDE     (         CALCULATE(             'Binary Classification Template'[Positive Conditions #]              ,FILTER(                 ALLSELECTED ('Binary Classification Template')                 ,                      'Binary Classification Template'[Percentile By Score]                      >                      MAX('Binary Classification Template'[Percentile By Score])             )         )               ,         CALCULATE(             'Binary Classification Template'[Total Population]             ,FILTER(                 ALLSELECTED ('Binary Classification Template')                 ,                      'Binary Classification Template'[Percentile By Score]                      >                      MAX('Binary Classification Template'[Percentile By Score])             )         )       )  //Divided by natural density  ,     DIVIDE     (         CALCULATE(             'Binary Classification Template'[Positive Conditions #]              ,FILTER(                 ALLSELECTED ('Binary Classification Template')                 ,                      'Binary Classification Template'[Percentile By Score]                      >                          0             )         )               ,         CALCULATE(             'Binary Classification Template'[Total Population]             ,FILTER(                 ALLSELECTED ('Binary Classification Template')                 ,                      'Binary Classification Template'[Percentile By Score]                      >                          0             )         )       )  )"
Measure,Binary Classification Template,"FN (Threshold) =  CALCULATE (    SUMX(         'Binary Classification Template'         ,IF(             AND(             'Binary Classification Template'[Raw Score] <= 'Thresholds'[PCP]             ,             'Binary Classification Template'[Actual] = 1             )             ,1             ,0         )     ) )    "
Measure,Binary Classification Template,"FP (Threshold) =  CALCULATE (    SUMX(         'Binary Classification Template'         ,IF(             AND(             'Binary Classification Template'[Raw Score] > 'Thresholds'[PCP]             ,             'Binary Classification Template'[Actual] = 0             )             ,1             ,0         )     ) )    "
Measure,Binary Classification Template,"TP (Threshold) =  CALCULATE (    SUMX(         'Binary Classification Template'         ,IF(             AND(             'Binary Classification Template'[Raw Score] > 'Thresholds'[PCP]             ,             'Binary Classification Template'[Actual] = 1             )             ,1             ,0         )     ) )    "
Measure,Binary Classification Template,"TN (Threshold) =  CALCULATE (    SUMX(         'Binary Classification Template'         ,IF(             AND(             'Binary Classification Template'[Raw Score] <= 'Thresholds'[PCP]             ,             'Binary Classification Template'[Actual] = 0             )             ,1             ,0         )     ) )    "
Measure,Binary Classification Template,"Precision (Threshold) = DIVIDE('Binary Classification Template'[TP (Threshold)],('Binary Classification Template'[TP (Threshold)]+'Binary Classification Template'[FP (Threshold)]))"
Measure,Binary Classification Template,"TPR/Recall (Threshold) = DIVIDE('Binary Classification Template'[TP (Threshold)],('Binary Classification Template'[TP (Threshold)]+'Binary Classification Template'[FN (Threshold)]))"
Measure,Binary Classification Template,"FPR (Threshold) = DIVIDE('Binary Classification Template'[FP (Threshold)],('Binary Classification Template'[TN (Threshold)]+'Binary Classification Template'[FP (Threshold)]),0)"
Measure,Thresholds,PCP = AVERAGE('Thresholds'[Threshold])
Measure,Threshold Plots,"AUC/ROC = SUMX('Threshold Plots',.01*'Threshold Plots'[TPR])"
Table,df,"let     Source = Python.Execute(""import pandas as pd#(lf)data = [[`Alex`,10],[`Bob`,12],[`Clarke`,13]]#(lf)df = pd.DataFrame(data,columns=[`Name`,`Age`],dtype=float)#(lf)print (df)""),     df1 = Source{[Name=""df""]}[Value] in     df1"
Table,DateTableTemplate_9e527bca-553c-41cb-bfd1-1b13c91e13a0,"Calendar(Date(2015,1,1), Date(2015,1,1))"
Table,df2,"let     Source = Python.Execute(""import pandas as pd #(lf)df = pd.DataFrame({ #(lf)    `Fname`:[`Harry`,`Sally`,`Paul`,`Abe`,`June`,`Mike`,`Tom`], #(lf)    `Age`:[21,34,42,18,24,80,22], #(lf)    `Weight`: [180, 130, 200, 140, 176, 142, 210], #(lf)    `Gender`:[`M`,`F`,`M`,`M`,`F`,`M`,`M`], #(lf)    `State`:[`Washington`,`Oregon`,`California`,`Washington`,`Nevada`,`Texas`,`Nevada`],#(lf)    `Children`:[4,1,2,3,0,2,0],#(lf)    `Pets`:[3,2,2,5,0,1,5] #(lf)}) #(lf)print (df)""),     df1 = Source{[Name=""df""]}[Value] in     df1"
Table,titanic,"let     Source = Csv.Document(File.Contents(""C:\ML_PBIX\titanic.csv""),[Delimiter="","", Columns=12, Encoding=1252, QuoteStyle=QuoteStyle.None]),     #""Promoted Headers"" = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),     #""Changed Type"" = Table.TransformColumnTypes(#""Promoted Headers"",{{""PassengerId"", Int64.Type}, {""Survived"", Int64.Type}, {""Pclass"", Int64.Type}, {""Name"", type text}, {""Sex"", type text}, {""Age"", type number}, {""SibSp"", Int64.Type}, {""Parch"", Int64.Type}, {""Ticket"", type text}, {""Fare"", type number}, {""Cabin"", type text}, {""Embarked"", type text}}) in     #""Changed Type"""
Table,churn_prediction,"let     Source = Csv.Document(File.Contents(""C:\ML_PBIX\churn_prediction.csv""),[Delimiter="","", Columns=20, Encoding=1252, QuoteStyle=QuoteStyle.None]),     #""Promoted Headers"" = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),     #""Changed Type"" = Table.TransformColumnTypes(#""Promoted Headers"",{{""customer_id"", Int64.Type}, {""vintage"", Int64.Type}, {""age"", Int64.Type}, {""gender"", type text}, {""dependents"", Int64.Type}, {""occupation"", type text}, {""customer_nw_category"", Int64.Type}, {""branch_code"", Int64.Type}, {""current_balance"", type number}, {""previous_month_end_balance"", type number}, {""average_monthly_balance_prevQ"", type number}, {""average_monthly_balance_prevQ2"", type number}, {""current_month_credit"", type number}, {""previous_month_credit"", type number}, {""current_month_debit"", type number}, {""previous_month_debit"", type number}, {""current_month_balance"", type number}, {""previous_month_balance"", type number}, {""churn"", Int64.Type}, {""last_transaction"", type date}}),     #""Removed Columns"" = Table.RemoveColumns(#""Changed Type"",{""last_transaction""}) in     #""Removed Columns"""
Table,jewellery_kmeans_model,"let     Source = Csv.Document(Web.Contents(""https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/jewellery.csv""),[Delimiter="","", Columns=4, Encoding=65001, QuoteStyle=QuoteStyle.None]),     #""Promoted Headers"" = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),     #""Changed Type"" = Table.TransformColumnTypes(#""Promoted Headers"",{{""Age"", Int64.Type}, {""Income"", Int64.Type}, {""SpendingScore"", type number}, {""Savings"", type number}}),     #""Run Python script"" = Python.Execute(""# `dataset` holds the input data for this script#(lf)from pycaret.clustering import *#(lf)dataset = get_clusters(dataset, model = `kmodes`, num_clusters = 6)"",[dataset=#""Changed Type""]),     dataset = #""Run Python script""{[Name=""dataset""]}[Value] in     dataset"
Table,anomaly,"let     Source = Csv.Document(Web.Contents(""https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/anomaly.csv""),[Delimiter="","", Columns=10, Encoding=65001, QuoteStyle=QuoteStyle.None]),     #""Promoted Headers"" = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),     #""Changed Type"" = Table.TransformColumnTypes(#""Promoted Headers"",{{""Col1"", type number}, {""Col2"", type number}, {""Col3"", type number}, {""Col4"", type number}, {""Col5"", type number}, {""Col6"", type number}, {""Col7"", type number}, {""Col8"", type number}, {""Col9"", type number}, {""Col10"", type number}}) in     #""Changed Type"""
Table,france_apriori_model,"let     Source = Csv.Document(Web.Contents(""https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/france.csv""),[Delimiter="","", Columns=8, Encoding=65001, QuoteStyle=QuoteStyle.None]),     #""Promoted Headers"" = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),     #""Changed Type"" = Table.TransformColumnTypes(#""Promoted Headers"",{{""InvoiceNo"", type text}, {""StockCode"", type text}, {""Description"", type text}, {""Quantity"", Int64.Type}, {""InvoiceDate"", type datetime}, {""UnitPrice"", type number}, {""CustomerID"", Int64.Type}, {""Country"", type text}}),     #""Run Python script"" = Python.Execute(""# `dataset` holds the input data for this script#(lf)from pycaret.arules import *#(lf)dataset = get_rules(dataset, transaction_id = `InvoiceNo`, item_id = `Description`)"",[dataset=#""Changed Type""]),     dataset = #""Run Python script""{[Name=""dataset""]}[Value],     #""Changed Type1"" = Table.TransformColumnTypes(dataset,{{""antecedents"", type text}, {""consequents"", type text}, {""antecedent support"", type number}, {""consequent support"", type number}, {""support"", type number}, {""confidence"", type number}, {""lift"", type number}, {""leverage"", type number}, {""conviction"", type text}}) in     #""Changed Type1"""
Table,employee_xgboost_model_trained,"let     Source = Csv.Document(Web.Contents(""https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/employee.csv""),[Delimiter="","", Columns=10, Encoding=65001, QuoteStyle=QuoteStyle.None]),     #""Promoted Headers"" = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),     #""Changed Type"" = Table.TransformColumnTypes(#""Promoted Headers"",{{""satisfaction_level"", type number}, {""last_evaluation"", type number}, {""number_project"", Int64.Type}, {""average_montly_hours"", Int64.Type}, {""time_spend_company"", Int64.Type}, {""Work_accident"", Int64.Type}, {""promotion_last_5years"", Int64.Type}, {""department"", type text}, {""salary"", type text}, {""left"", Int64.Type}}),     #""Run Python script"" = Python.Execute(""# `dataset` holds the input data for this script#(lf)# import classification module and setup environment#(lf)from pycaret.classification import *#(lf)clf1 = setup(dataset, target = `left`, silent = True)#(lf)# train and save ada model#(lf)mdl = create_model(`ada`, verbose = False)#(lf)mdlfin = finalize_model(mdl)#(lf)save_model(mdlfin, `C:\\2022_01_DSI_WD\\ada_powerbi`)#(lf)     "",[dataset=#""Changed Type""]),     dataset = #""Run Python script""{[Name=""dataset""]}[Value],     #""Changed Type1"" = Table.TransformColumnTypes(dataset,{{""satisfaction_level"", type number}, {""last_evaluation"", type number}, {""number_project"", Int64.Type}, {""average_montly_hours"", Int64.Type}, {""time_spend_company"", Int64.Type}, {""Work_accident"", Int64.Type}, {""promotion_last_5years"", Int64.Type}, {""department"", type text}, {""salary"", type text}, {""left"", Int64.Type}}) in     #""Changed Type1"""
Table,boston,"let     Source = Csv.Document(Web.Contents(""https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/boston.csv""),[Delimiter="","", Columns=14, Encoding=65001, QuoteStyle=QuoteStyle.None]),     #""Promoted Headers"" = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),     #""Changed Type"" = Table.TransformColumnTypes(#""Promoted Headers"",{{""crim"", type number}, {""zn"", type number}, {""indus"", type number}, {""chas"", Int64.Type}, {""nox"", type number}, {""rm"", type number}, {""age"", type number}, {""dis"", type number}, {""rad"", Int64.Type}, {""tax"", Int64.Type}, {""ptratio"", type number}, {""black"", type number}, {""lstat"", type number}, {""medv"", type number}}) in     #""Changed Type"""
Table,jewellery,"let     Source = Csv.Document(Web.Contents(""https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/jewellery.csv""),[Delimiter="","", Columns=4, Encoding=65001, QuoteStyle=QuoteStyle.None]),     #""Promoted Headers"" = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),     #""Changed Type"" = Table.TransformColumnTypes(#""Promoted Headers"",{{""Age"", Int64.Type}, {""Income"", Int64.Type}, {""SpendingScore"", type number}, {""Savings"", type number}}) in     #""Changed Type"""
Table,anomaly_knn_model,"let     Source = anomaly,     #""Run Python script"" = Python.Execute(""# `dataset` holds the input data for this script#(lf)from pycaret.anomaly import *#(lf)dataset = get_outliers(data = dataset)"",[dataset=Source]),     dataset = #""Run Python script""{[Name=""dataset""]}[Value],     #""Changed Type"" = Table.TransformColumnTypes(dataset,{{""Col1"", type number}, {""Col2"", type number}, {""Col3"", type number}, {""Col4"", type number}, {""Col5"", type number}, {""Col6"", type number}, {""Col7"", type number}, {""Col8"", type number}, {""Col9"", type number}, {""Col10"", type number}, {""Anomaly"", Int64.Type}, {""Anomaly_Score"", type number}}),     #""Sorted Rows"" = Table.Sort(#""Changed Type"",{{""Anomaly"", Order.Ascending}, {""Anomaly_Score"", Order.Ascending}})     in     #""Sorted Rows"""
Table,kiva,"let     Source = Csv.Document(Web.Contents(""https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/kiva.csv""),[Delimiter="","", Columns=7, Encoding=65001, QuoteStyle=QuoteStyle.Csv]),     #""Promoted Headers"" = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),     #""Changed Type"" = Table.TransformColumnTypes(#""Promoted Headers"",{{""country"", type text}, {""en"", type text}, {""gender"", type text}, {""loan_amount"", Int64.Type}, {""nonpayment"", type text}, {""sector"", type text}, {""status"", Int64.Type}}) in #""Changed Type"""
Table,france,"let     Source = Csv.Document(Web.Contents(""https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/france.csv""),[Delimiter="","", Columns=8, Encoding=65001, QuoteStyle=QuoteStyle.None]),     #""Promoted Headers"" = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),     #""Changed Type"" = Table.TransformColumnTypes(#""Promoted Headers"",{{""InvoiceNo"", type text}, {""StockCode"", type text}, {""Description"", type text}, {""Quantity"", Int64.Type}, {""InvoiceDate"", type datetime}, {""UnitPrice"", type number}, {""CustomerID"", Int64.Type}, {""Country"", type text}}) in     #""Changed Type"""
Table,LocalDateTable_5afb9adf-1dc0-49d6-aedd-b3e605680c87,"Calendar(Date(Year(MIN(`france`[InvoiceDate])), 1, 1), Date(Year(MAX(`france`[InvoiceDate])), 12, 31))"
Table,employee_xgboost_model_applied,"let     Source = Csv.Document(Web.Contents(""https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/employee.csv""),[Delimiter="","", Columns=10, Encoding=65001, QuoteStyle=QuoteStyle.None]),     #""Promoted Headers"" = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),     #""Changed Type"" = Table.TransformColumnTypes(#""Promoted Headers"",{{""satisfaction_level"", type number}, {""last_evaluation"", type number}, {""number_project"", Int64.Type}, {""average_montly_hours"", Int64.Type}, {""time_spend_company"", Int64.Type}, {""Work_accident"", Int64.Type}, {""promotion_last_5years"", Int64.Type}, {""department"", type text}, {""salary"", type text}, {""left"", Int64.Type}}),     #""Run Python script"" = Python.Execute(""from pycaret.classification import *#(lf)ada= load_model(`C:\\2022_01_DSI_WD\\ada_powerbi`)#(lf)dataset = predict_model(ada, data = dataset)"",[dataset=#""Changed Type""]),     dataset = #""Run Python script""{[Name=""dataset""]}[Value],     #""Changed Type1"" = Table.TransformColumnTypes(dataset,{{""satisfaction_level"", type number}, {""last_evaluation"", type number}, {""number_project"", Int64.Type}, {""average_montly_hours"", Int64.Type}, {""time_spend_company"", Int64.Type}, {""Work_accident"", Int64.Type}, {""promotion_last_5years"", Int64.Type}, {""department"", type text}, {""salary"", type text}, {""left"", Int64.Type}, {""Label"", Int64.Type}, {""Score"", type number}}) in     #""Changed Type1"""
Table,boston (2),"let     Source = Csv.Document(Web.Contents(""https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/boston.csv""),[Delimiter="","", Columns=14, Encoding=65001, QuoteStyle=QuoteStyle.None]),     #""Promoted Headers"" = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),     #""Changed Type"" = Table.TransformColumnTypes(#""Promoted Headers"",{{""crim"", type number}, {""zn"", type number}, {""indus"", type number}, {""chas"", Int64.Type}, {""nox"", type number}, {""rm"", type number}, {""age"", type number}, {""dis"", type number}, {""rad"", Int64.Type}, {""tax"", Int64.Type}, {""ptratio"", type number}, {""black"", type number}, {""lstat"", type number}, {""medv"", type number}}) in     #""Changed Type"""
Table,cars_reg_price_dt,"let     Source = Csv.Document(AzureStorage.BlobContents(""https://202110dsiwd5688753966.blob.core.windows.net/azureml-blobstore-5aea756e-53ac-49ff-a15b-dbc1bc0967cf/cars_reg_price_dt""),[Delimiter="","", Columns=26, Encoding=1252, QuoteStyle=QuoteStyle.None]),     #""Promoted Headers"" = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),     #""Changed Type"" = Table.TransformColumnTypes(#""Promoted Headers"",{{""symboling"", Int64.Type}, {""CarName"", type text}, {""fueltype"", type text}, {""aspiration"", type text}, {""doornumber"", type text}, {""carbody"", type text}, {""drivewheel"", type text}, {""enginelocation"", type text}, {""wheelbase"", type number}, {""carlength"", type number}, {""carwidth"", type number}, {""carheight"", type number}, {""curbweight"", Int64.Type}, {""enginetype"", type text}, {""cylindernumber"", type text}, {""enginesize"", Int64.Type}, {""fuelsystem"", type text}, {""boreratio"", type number}, {""stroke"", type number}, {""compressionratio"", type number}, {""horsepower"", Int64.Type}, {""peakrpm"", Int64.Type}, {""citympg"", Int64.Type}, {""highwaympg"", Int64.Type}, {""price"", type number}, {""Scored Labels"", type number}}),     #""Removed Other Columns"" = Table.SelectColumns(#""Changed Type"",{""boreratio"", ""carbody"", ""carheight"", ""carlength"", ""CarName"", ""carwidth"", ""citympg"", ""curbweight"", ""cylindernumber"", ""drivewheel"", ""enginesize"", ""highwaympg"", ""horsepower"", ""peakrpm"", ""price"", ""Scored Labels"", ""wheelbase""}) in     #""Removed Other Columns"""
Table,Cut Score,"GENERATESERIES(0, 1, 0.01)"
Table,udfDates,"let     Source = Sql.Database(""localhost"", ""AdventureWorksDW2019""),     dbo_udfDates = Source{[Schema=""dbo"",Item=""udfDates""]}[Data],     #""Invoked Functiondbo_udfDates1"" = dbo_udfDates(DayName, MonthName) in     #""Invoked Functiondbo_udfDates1"""
Table,Threshold,"let     Source = Python.Execute(""import pandas as pd#(lf)data = [[str(round(x * .01,2)), round(x * .01,2)] for x in range(1,101)]#(lf)df = pd.DataFrame(data,columns=[`Threshold`,`ThresholdValue`])#(lf)print (df)""),     df1 = Source{[Name=""df""]}[Value],     #""Changed Type"" = Table.TransformColumnTypes(df1,{{""ThresholdValue"", type number}}) in     #""Changed Type"""
Table,Day,"let     Source = Table.FromRows(Json.Document(Binary.Decompress(Binary.FromText(""i45W8s3PS0msVNJRMlSK1YlWCilNLYbwjcD88NSUPJiIMURFRmkRVMAELOBWlAnhmoK5wYklpUUQATOIQCnUBnOl2FgA"", BinaryEncoding.Base64), Compression.Deflate)), let _t = ((type nullable text) meta [Serialized.Text = true]) in type table [Day = _t, NumDay = _t]),     #""Changed Type"" = Table.TransformColumnTypes(Source,{{""Day"", type text}, {""NumDay"", Int64.Type}}) in     #""Changed Type"""
Table,Month,"let     Source = Table.FromRows(Json.Document(Binary.Decompress(Binary.FromText(""i45W8krMK00sqlTSUTJUitWJVnJLTSqCChiBBXwTi5IzgDxjMM+xoCgzB8gzgcqB1JmC2V6lealAjhmUkwOSMYfoKU0vLS4Bci3A3ODUgpLU3KTUIqCIJVjEP7kkH8I3NAAL+OWXwVQYQpzlkpoMFwG6KxYA"", BinaryEncoding.Base64), Compression.Deflate)), let _t = ((type nullable text) meta [Serialized.Text = true]) in type table [Month = _t, NumMonth = _t]),     #""Changed Type"" = Table.TransformColumnTypes(Source,{{""Month"", type text}, {""NumMonth"", Int64.Type}}) in     #""Changed Type"""
Table,Query1,"let     Source = #sections,     Section1 = Source[Section1],     #""Converted to Table"" = Record.ToTable(Section1),     #""Add TableTest"" = Table.AddColumn(#""Converted to Table"", ""TableTest"", each try Table.ColumnCount([Value]) otherwise -1, Int64.Type),     #""Filtered Rows"" = Table.SelectRows(#""Add TableTest"", each [TableTest] > -1) in     #""Filtered Rows"""
Table,evalCase,"SUMMARIZECOLUMNS(employee_xgboost_model_applied[last_evaluation],""NumCases"",[Cases])"
Table,auto_price_residual,"let     Source = Parquet.Document(File.Contents(""C:\ML_PBIX\data.dataset.parquet""), [Compression=null, LegacyColumnNameEncoding=false, MaxDepth=null]) in     Source"
Table,Problem Children,"FILTER(auto_price_residual,auto_price_residual[Residiual] <=1673.70)"
Table,Binary Classification Template," SELECTCOLUMNS(     employee_xgboost_model_applied     //output of model     ,""Raw Score"", employee_xgboost_model_applied[Score]     //input of target     ,""Actual"", employee_xgboost_model_applied[left]     //features for residual analysis     ,""average_montly_hours"",employee_xgboost_model_applied[average_montly_hours]     ,""number_project"",employee_xgboost_model_applied[number_project]     ,""last_evaluation"",employee_xgboost_model_applied[last_evaluation]     ,""time_spend_company"",employee_xgboost_model_applied[time_spend_company]     ,""satisfaction_level"",employee_xgboost_model_applied[satisfaction_level]     ,""promotion_last_5years"",employee_xgboost_model_applied[promotion_last_5years]         ,""Work_accident"",employee_xgboost_model_applied[Work_accident] )"
Table,Thresholds,"GENERATESERIES(0, 1, 0.01)"
Table,Threshold Plots,"     SUMMARIZECOLUMNS(         `Thresholds`[Threshold]         ,""TPR"",`Binary Classification Template`[TPR/Recall (Threshold)]         ,""Recall"",`Binary Classification Template`[TPR/Recall (Threshold)]         ,""Precision"",`Binary Classification Template`[Precision (Threshold)]         ,""FPR"",`Binary Classification Template`[FPR (Threshold)]     )"
