@inproceedings{Mann2006,
address = {New York, New York, USA},
author = {Mann, Gideon S. and Mimno, David and McCallum, Andrew},
booktitle = {Proceedings of the 6th ACM/IEEE-CS joint conference on Digital libraries - JCDL '06},
doi = {10.1145/1141753.1141765},
file = {:Users/storopoli/Documents/Mendeley Desktop/mann2006.pdf:pdf},
isbn = {1595933549},
pages = {65},
publisher = {ACM Press},
title = {{Bibliometric impact measures leveraging topic analysis}},
url = {http://portal.acm.org/citation.cfm?doid=1141753.1141765},
year = {2006}
}
@article{Mimno2011,
author = {Mimno, David and Wallach, Hanna M. and Talley, Edmund and Leenders, Miriam and McCallum, Andrew},
file = {:Users/storopoli/Documents/Mendeley Desktop/Mimno et al. - 2011 - Optimizing semantic coherence in topic models.pdf:pdf},
isbn = {978-1-937284-11-4},
journal = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
pages = {262--272},
publisher = {Association for Computational Linguistics},
title = {{Optimizing semantic coherence in topic models}},
url = {https://dl.acm.org/citation.cfm?id=2145462},
year = {2011}
}
@incollection{Boyd-Graber2014,
abstract = {Topic models are a versatile tool for understanding corpora, but they are not perfect. In this chapter, we describe the problems users often encounter when using topic models for the first time. We begin with the preprocessing choices users must make when creating a corpus for topic modeling for the first time, followed by options users have for running topic models. After a user has a topic model learned from data, we describe how users know whether they have a good topic model or not and give a summary of the common problems users have, and how those problems can be addressed and solved by recent advances in both models and tools.},
address = {Boca Raton, FL},
author = {Boyd-Graber, J and Mimno, D and Newman, D},
booktitle = {Handbook of Mixed Membership Models and their Applications},
chapter = {12},
editor = {{Edoardo M. Airoldi} and {David M. Blei} and {Elena A. Erosheva} and {Stephen E. Fienberg}},
file = {:Users/storopoli/Documents/Mendeley Desktop/Boyd-Graber, Mimno, Newman - 2014 - Care and feeding of topic models Problems, diagnostics, and improvements.pdf:pdf},
isbn = {9781466504080},
pages = {225--254},
publisher = {CRC Press},
title = {{Care and feeding of topic models: Problems, diagnostics, and improvements}},
url = {http://www.people.fas.harvard.edu/{~}airoldi/pub/books/b02.AiroldiBleiEroshevaFienberg2014HandbookMMM/Ch12{\_}MMM2014.pdf},
year = {2014}
}
@article{Kaplan2015,
author = {Kaplan, Sarah and Vakili, Keyvan},
doi = {10.1002/smj.2294},
file = {:Users/storopoli/Documents/Mendeley Desktop/Kaplan, Vakili - 2015 - The double-edged sword of recombination in breakthrough innovation.pdf:pdf},
issn = {01432095},
journal = {Strategic Management Journal},
keywords = {breakthrough innovation,cognition,creativity,patents,recombination,topic modeling},
month = {oct},
number = {10},
pages = {1435--1457},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{The double-edged sword of recombination in breakthrough innovation}},
url = {http://doi.wiley.com/10.1002/smj.2294},
volume = {36},
year = {2015}
}
@article{Teh2006,
abstract = {We consider problems involving groups of data where each observation within a group is a draw from a mixture model and where it is desirable to share mixture components between groups. We assume that the number of mixture components is unknown a priori and is to be inferred from the data. In this setting it is natural to consider sets of Dirichlet processes, one for each group, where the well-known clustering property of the Dirichlet process provides a nonparametric prior for the number of mixture components within each group. Given our desire to tie the mixture models in the various groups, we consider a hierarchical model, specifically one in which the base measure for the child Dirichlet processes is itself distributed according to a Dirichlet process. Such a base measure being discrete, the child Dirichlet processes necessarily share atoms. Thus, as desired, the mixture models in the different groups necessarily share mixture components. We discuss representations of hierarchical Dirichlet processes in terms of a stick-breaking process, and a generalization of the Chinese restaurant process that we refer to as the “Chinese restaurant franchise.” We present Markov chain Monte Carlo algorithms for posterior inference in hierarchical Dirichlet process mixtures and describe applications to problems in information retrieval and text modeling.},
author = {Teh, Yee Whye and Jordan, Michael I and Beal, Matthew J and Blei, David M},
doi = {10.1198/016214506000000302},
file = {:Users/storopoli/Documents/Mendeley Desktop/Hierarchical Dirichlet Processes.pdf:pdf},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Clustering,Hierarchical model,Markov chain Monte Carlo,Mixture model,Nonparametric Bayesian statistics},
month = {dec},
number = {476},
pages = {1566--1581},
publisher = {Taylor {\&} Francis},
title = {{Hierarchical Dirichlet processes}},
url = {http://www.tandfonline.com/doi/abs/10.1198/016214506000000302},
volume = {101},
year = {2006}
}
@article{Kaur2018,
abstract = {ABSTRACTOnline privacy policies are known to have inconsistent formats and incomplete content. They are also hard to understand and do not effectively help individuals to make decisions about the data practices of the online service providers. Several studies have focused on the deficiencies of privacy policies such as length and readability. However, a very limited number of studies have explored the content of privacy policies. This paper aims to shed some lights on the content of these legal documents. To this end, we performed a comprehensive analysis of keywords and content of over 2000 online policies. Policies were collected from variety of websites, application domains, and regulatory regimes. Topic modeling algorithms, such as Latent Dirichlet Allocation, were used for topic coverage analysis. This study also measured the coverage of ambiguous words in privacy policies. Lastly, a method was used to evaluate keyword similarity between privacy policies which belonged to different regulatory framewo...},
author = {Kaur, Jasmin and Dara, Rozita A. and Obimbo, Charlie and Song, Fei and Menard, Karen},
doi = {10.1080/19393555.2019.1606368},
file = {:Users/storopoli/Documents/Mendeley Desktop/A comprehensive keyword analysis of online privacy policies.pdf:pdf},
issn = {1939-3555},
journal = {Information Security Journal: A Global Perspective},
keywords = {Privacy policies,keyword analysis,regulations,seed keywords,topic modelling},
month = {nov},
number = {5-6},
pages = {260--275},
publisher = {Taylor {\&} Francis},
title = {{A comprehensive keyword analysis of online privacy policies}},
url = {https://www.tandfonline.com/doi/full/10.1080/19393555.2019.1606368},
volume = {27},
year = {2018}
}
@article{Maier2018,
abstract = {Latent Dirichlet allocation (LDA) topic models are increasingly being used in communication research. Yet, questions regarding reliability and validity of the approach have received little attention thus far. In applying LDA to textual data, researchers need to tackle at least four major challenges that affect these criteria: (a) appropriate pre-processing of the text collection; (b) adequate selection of model parameters, including the number of topics to be generated; (c) evaluation of the model's reliability; and (d) the process of validly interpreting the resulting topics. We review the research literature dealing with these questions and propose a methodology that approaches these challenges. Our overall goal is to make LDA topic modeling more accessible to communication researchers and to ensure compliance with disciplinary standards. Consequently, we develop a brief hands-on user guide for applying LDA topic modeling. We demonstrate the value of our approach with empirical data from an ongoing research project.},
author = {Maier, Daniel and Waldherr, A. and Miltner, P. and Wiedemann, G. and Niekler, A. and Keinert, A. and Pfetsch, B. and Heyer, G. and Reber, U. and H{\"{a}}ussler, T. and Schmid-Petri, H. and Adam, S.},
doi = {10.1080/19312458.2018.1430754},
file = {:Users/storopoli/Documents/Mendeley Desktop/Applying LDA Topic Modeling in Communication Research Toward a Valid and Reliable Methodology.pdf:pdf},
issn = {19312466},
journal = {Communication Methods and Measures},
month = {apr},
number = {2-3},
pages = {93--118},
publisher = {Routledge},
title = {{Applying LDA Topic Modeling in Communication Research: Toward a Valid and Reliable Methodology}},
url = {https://www.tandfonline.com/doi/full/10.1080/19312458.2018.1430754},
volume = {12},
year = {2018}
}
@article{Nikolenko2017,
abstract = {Qualitative studies, such as sociological research, opinion analysis and media studies, can benefit greatly from automated topic mining provided by topic models such as latent Dirichlet allocation (LDA). However, examples of qualitative studies that employ topic modelling as a tool are currently few and far between. In this work, we identify two important problems along the way to using topic models in qualitative studies: lack of a good quality metric that closely matches human judgement in understanding topics and the need to indicate specific subtopics that a specific qualitative study may be most interested in mining. For the first problem, we propose a new quality metric, tf-idf coherence, that reflects human judgement more accurately than regular coherence, and conduct an experiment to verify this claim. For the second problem, we propose an interval semi-supervised approach (ISLDA) where certain predefined sets of keywords (that define the topics researchers are interested in) are restricted to specific intervals of topic assignments. Our experiments show that ISLDA is better for topic extraction than LDA in terms of tf-idf coherence, number of topics identified to predefined keywords and topic stability. We also present a case study on a Russian LiveJournal dataset aimed at ethnicity discourse analysis.},
author = {Nikolenko, Sergey I. and Koltcov, Sergei and Koltsova, Olessia},
doi = {10.1177/0165551515617393},
file = {:Users/storopoli/Documents/Mendeley Desktop/0165551515617393.pdf:pdf},
issn = {17416485},
journal = {Journal of Information Science},
keywords = {LDA extensions,Latent Dirichlet allocation,topic modelling,topic quality},
month = {feb},
number = {1},
pages = {88--102},
publisher = {SAGE PublicationsSage UK: London, England},
title = {{Topic modelling for qualitative studies}},
url = {http://journals.sagepub.com/doi/10.1177/0165551515617393},
volume = {43},
year = {2017}
}
@article{Veitch2019,
abstract = {We address causal inference with text documents. For example, does adding a theorem to a paper affect its chance of acceptance? Does reporting the gender of a forum post author affect the popularity of the post? We estimate these effects from observational data, where they may be confounded by features of the text such as the subject or writing quality. Although the text suffices for causal adjustment, it is prohibitively high-dimensional. The challenge is to find a low-dimensional text representation that can be used in causal inference. A key insight is that causal adjustment requires only the aspects of text that are predictive of both the treatment and outcome. Our proposed method adapts deep language models to learn low-dimensional embeddings from text that predict these values well; these embeddings suffice for causal adjustment. We establish theoretical properties of this method. We study it empirically on semi-simulated and real data on paper acceptance and forum post popularity. Code is available at https://github.com/blei-lab/causal-text-embeddings.},
archivePrefix = {arXiv},
arxivId = {1905.12741},
author = {Veitch, Victor and Sridhar, Dhanya and Blei, David M.},
eprint = {1905.12741},
file = {:Users/storopoli/Documents/Mendeley Desktop/Veitch, Sridhar, Blei - 2019 - Using Text Embeddings for Causal Inference.pdf:pdf},
month = {may},
title = {{Using Text Embeddings for Causal Inference}},
url = {http://arxiv.org/abs/1905.12741},
year = {2019}
}
@article{Debortoli2016,
author = {Debortoli, Stefan and M{\"{u}}ller, Oliver and Junglas, Iris and vom Brocke, Jan},
doi = {10.17705/1CAIS.03907},
file = {:Users/storopoli/Documents/Mendeley Desktop/TextMiningForInformationSystemsResearchers.pdf:pdf},
issn = {15293181},
journal = {Communications of the Association for Information Systems},
month = {jul},
number = {1},
pages = {110--135},
title = {{Text Mining for Information Systems Researchers: An Annotated Topic Modeling Tutorial}},
url = {http://aisel.aisnet.org/cais/vol39/iss1/7/},
volume = {39},
year = {2016}
}
@article{Szekely2017,
abstract = {Organizations are increasingly using sustainability reports to inform their stakeholders and the public about their sustainability practices. We apply topic modelling to 9,514 sustainability reports published between 1999 and 2015 in order to identify common topics and, thus, the most common practices described in these reports. In particular, we identify forty-two topics that reflect sustainability and focus on the coverage and trends of economic, environmental, and social sustainability topics. Among the first to analyse such a large amount of data on organizations' sustainability reporting, the paper serves as an example of how to apply natural language processing as a strategy of inquiry in sustainability research. The paper also derives from the data analysis ten propositions for future research and practice that are of immediate value for organizations and researchers.},
author = {Szekely, Nadine and {Vom Brocke}, Jan},
doi = {10.1371/journal.pone.0174807},
editor = {Srinivasan, Rajagopalan},
file = {:Users/storopoli/Documents/Mendeley Desktop/Sz{\'{e}}kely, vom Brocke - 2017 - What can we learn from corporate sustainability reporting Deriving propositions for research and practice.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
month = {apr},
number = {4},
pages = {e0174807},
publisher = {Public Library of Science},
title = {{What can we learn from corporate sustainability reporting? Deriving propositions for research and practice from over 9,500 corporate sustainability reports published between 1999 and 2015 using topic modelling technique}},
url = {https://dx.plos.org/10.1371/journal.pone.0174807},
volume = {12},
year = {2017}
}
@unpublished{Jelveh2014,
abstract = {Does political ideology influence economic research? We rely upon purely inductive methods in natural language processing and machine learning to examine patterns of implicit political ideology in economic articles. Using observed political behavior of economists and the phrases from their academic articles, we construct a high-dimensional predictor of political ideology by article, economist, school, and journal. In addition to field, journal, and editor ideology, we look at the correlation of author ideology with magnitudes of reported policy relevant elasticities. Overall our results suggest that there is substantial sorting by ideology into fields, departments, and methodologies, and that political ideology influences the results of economic research.},
author = {Jelveh, Zubin and Kogut, Bruce and Naidu, Suresh},
booktitle = {SSRN},
doi = {10.2139/ssrn.2535453},
file = {:Users/storopoli/Documents/Mendeley Desktop/SSRN-id2535453.pdf:pdf},
issn = {1556-5068},
month = {sep},
title = {{Political Language in Economics}},
url = {http://www.ssrn.com/abstract=2535453},
year = {2014}
}
@article{DiMaggio2015,
abstract = {Social scientists and computer scientist are divided by small differences in perspective and not by any significant disciplinary divide. In the field of text analysis, several such differences are noted: social scientists often use unsupervised models to explore corpora, whereas many computer scientists employ supervised models to train data; social scientists hold to more conventional causal notions than do most computer scientists, and often favor intense exploitation of existing algorithms, whereas computer scientists focus more on developing new models; and computer scientists tend to trust human judgment more than social scientists do. These differences have implications that potentially can improve the practice of social science.},
author = {DiMaggio, Paul},
doi = {10.1177/2053951715602908},
file = {:Users/storopoli/Documents/Mendeley Desktop/2053951715602908.pdf:pdf},
issn = {2053-9517},
journal = {Big Data {\&} Society},
keywords = {Topic models,interpretation,sentiment analysis,supervised models,text analysis,unsupervised models},
month = {dec},
number = {2},
pages = {205395171560290},
publisher = {SAGE PublicationsSage UK: London, England},
title = {{Adapting computational text analysis to social science (and vice versa)}},
url = {http://journals.sagepub.com/doi/10.1177/2053951715602908},
volume = {2},
year = {2015}
}
@article{Mohr2013,
abstract = {Poetics, 41 (2013) 545-569. doi:10.1016/j.poetic.2013.10.001},
author = {Mohr, John W. and Bogdanov, Petko},
doi = {10.1016/j.poetic.2013.10.001},
file = {:Users/storopoli/Documents/Mendeley Desktop/Mohr - 2013 - Introduction—Topic models What they are and why they matter.pdf:pdf},
issn = {0304422X},
journal = {Poetics},
month = {dec},
number = {6},
pages = {545--569},
publisher = {North-Holland},
title = {{Introduction—Topic models: What they are and why they matter}},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X13000685},
volume = {41},
year = {2013}
}
@article{DiMaggio2013,
abstract = {Topic modeling provides a valuable method for identifying the linguistic contexts that surround social institutions or policy domains. This article uses Latent Dirichlet Allocation (LDA) to analyze how one such policy domain, government assistance to artists and arts organizations, was framed in almost 8000 articles. These comprised all articles that referred to government support for the arts in the U.S. published in five U.S. newspapers between 1986 and 1997-a period during which such assistance, once noncontroversial, became a focus of contention. We illustrate the strengths of topic modeling as a means of analyzing large text corpora, discuss the proper choice of models and interpretation of model results, describe means of validating topic-model solutions, and demonstrate the use of topic models in combination with other statistical tools to estimate differences between newspapers in the prevalence of different frames. Throughout, we emphasize affinities between the topic-modeling approach and such central concepts in the study of culture as framing, polysemy, heteroglossia, and the relationality of meaning. {\textcopyright} 2013 Elsevier B.V.},
author = {DiMaggio, Paul and Nag, Manish and Blei, David},
doi = {10.1016/j.poetic.2013.08.004},
file = {:Users/storopoli/Documents/Mendeley Desktop/DiMaggio, Nag, Blei - 2013 - Exploiting affinities between topic modeling and the sociological perspective on culture Application to new.pdf:pdf},
issn = {0304422X},
journal = {Poetics},
keywords = {Content analysis,Heteroglossia,Meaning,National Endowment for the Arts,Polysemy,Topic models},
month = {dec},
number = {6},
pages = {570--606},
publisher = {North-Holland},
title = {{Exploiting affinities between topic modeling and the sociological perspective on culture: Application to newspaper coverage of U.S. government arts funding}},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X13000661},
volume = {41},
year = {2013}
}
@inproceedings{Wang2011,
abstract = {Researchers have access to large online archives of scientiﬁc arti- cles. As a consequence, ﬁnding relevant papers has become more difﬁcult. Newly formed online communities of researchers sharing citations provides a new way to solve this problem. In this paper, we develop an algorithm to recommend scientiﬁc articles to users of an online community. Our approach combines the merits of traditional collaborative ﬁltering and probabilistic topic modeling. It provides an interpretable latent structure for users and items, and can form recommendations about both existing and newly published articles. We study a large subset of data from CiteULike, a bibliography shar- ing service, and show that our algorithm provides a more effective recommender system than traditional collaborative ﬁltering.},
address = {New York, New York, USA},
author = {Wang, Chong and Blei, David M.},
booktitle = {Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '11},
doi = {10.1145/2020408.2020480},
file = {:Users/storopoli/Documents/Mendeley Desktop/p448-wang.pdf:pdf},
isbn = {9781450308137},
pages = {448},
publisher = {ACM Press},
title = {{Collaborative topic modeling for recommending scientific articles}},
url = {http://dl.acm.org/citation.cfm?doid=2020408.2020480},
year = {2011}
}
@article{Rehurek2010,
abstract = {Large corpora are ubiquitous in today's world and memory quickly becomes the limiting factor in practical applications of the Vector Space Model (VSM). In this paper, we identify a gap in existing implementations of many of the popular algorithms, which is their scalability and ease of use. We describe a Natural Language Processing software framework which is based on the idea of document streaming, i.e. processing corpora document after document, in a memory independent fashion. Within this framework, we implement several popular algorithms for topical inference, including Latent Semantic Analysis and Latent Dirichlet Allocation, in a way that makes them completely independent of the training corpus size. Particular emphasis is placed on straightforward and intuitive framework design, so that modifications and extensions of the methods and/or their application by interested practitioners are effortless. We demonstrate the usefulness of our approach on a real-world scenario of computing document similarities within an existing digital library DML-CZ.},
author = {Rehurek, Radim and Sojka, Petr},
file = {:Users/storopoli/Documents/Mendeley Desktop/10.1.1.695.4595.pdf:pdf},
isbn = {2-9517408-6-7},
journal = {LREC Workshop on New Challenges for NLP Frameworks},
pages = {45--50},
title = {{Software framework for topic modelling with large corpora}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.695.4595 http://www.muni.cz/research/publications/884893},
year = {2010}
}
@misc{Steyvers2007,
abstract = {Many chapters in this book illustrate that applying a statistical method such as latent semantic analysis (LSA; Landauer {\&} Dumais, 1997; Landauer, Foltz, {\&} Laham, 1998) to large databases can yield insight into human cognition. The LSA approach makes three claims: that semantic information can be derived from a word-document co-occurrence matrix; that dimensionality reduction is an essential part of this derivation; and that words and documents can be represented as points in Euclidean space. This chapter pursues an approach that is consistent with the first two of these claims, but differs in the third, describing a class of statistical models in which the semantic properties of words and documents are expressed in terms of probabilistic topics. The plan of this chapter is as follows. First, it describes the key ideas behind topic models in more detail and outlines how it is possible to identify the topics that appear in a set of documents. It then discusses methods for answering two kinds of questions about similarities: assessing the similarity between two documents and assessing the associative similarity between two words. It closes by considering how generative models have the potential to provide further insight into human cognition. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
address = {Mahwah, NJ, US},
author = {Steyvers, Mark and Griffiths, Tom},
booktitle = {Handbook of latent semantic analysis.},
file = {:Users/storopoli/Documents/Mendeley Desktop/05563111.pdf:pdf},
isbn = {0-8058-5418-5 (Hardcover); 1-4106-1534-0 (PDF); 978-0-8058-5418-3 (Hardcover); 978-1-4106-1534-3 (PDF)},
keywords = {*Analysis,*Cognition,*Models,*Semantics,Statistical Probability},
pages = {427--448},
publisher = {Lawrence Erlbaum Associates Publishers},
title = {{Probabilistic topic models.}},
year = {2007}
}
@article{Blei2003,
author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
file = {:Users/storopoli/Documents/Mendeley Desktop/Blei, Ng, Jordan - 2003 - Latent Dirichlet Allocation.pdf:pdf},
issn = {ISSN 1533-7928},
journal = {Journal of Machine Learning Research},
number = {Jan},
pages = {993--1022},
title = {{Latent Dirichlet Allocation}},
url = {http://www.jmlr.org/papers/v3/blei03a.html},
volume = {3},
year = {2003}
}
@article{Blei2007,
abstract = {Topic models, such as latent Dirichlet allocation (LDA), can be useful tools for the statistical analysis of document collections and other discrete data. The LDA model assumes that the words of each document arise from a mixture of topics, each of which is a distribution over the vocabulary. A lim- itation of LDA is the inability to model topic correlation even though, for example, a document about genetics is more likely to also be about disease than X-ray astronomy. This limitation stems from the use of the Dirichlet dis- tribution to model the variability among the topic proportions. In this paper we develop the correlated topic model (CTM), where the topic proportions exhibit correlation via the logistic normal distribution [J. Roy. Statist. Soc. Ser. B 44 (1982) 139–177]. We derive a fast variational inference algorithm for approximate posterior inference in this model, which is complicated by the fact that the logistic normal is not conjugate to the multinomial. We ap- ply the CTM to the articles from Science published from 1990–1999, a data set that comprises 57M words. The CTM gives a better fit of the data than LDA, and we demonstrate its use as an exploratory tool of large document collections.},
author = {Blei, David M. and Lafferty, John D.},
doi = {10.1214/07-aoas136},
file = {:Users/storopoli/Documents/Mendeley Desktop/euclid.aoas.1183143727.pdf:pdf},
issn = {1932-6157},
journal = {The Annals of Applied Statistics},
keywords = {Hierarchical models,approximate posterior inference,text analysis,variational methods},
month = {jun},
number = {1},
pages = {17--35},
publisher = {Institute of Mathematical Statistics},
title = {{A correlated topic model of Science}},
url = {http://projecteuclid.org/euclid.aoas/1183143727},
volume = {1},
year = {2007}
}
@inproceedings{Blei2006,
abstract = {A family of probabilistic time series models is developed to analyze the time evolution of topics in large document collections. The approach is to use state space models on the natural parameters of the multinomial distributions that represent the topics},
address = {New York, New York, USA},
author = {Blei, David M. and Lafferty, John D.},
booktitle = {Proceedings of the 23rd international conference on Machine learning - ICML '06},
doi = {10.1145/1143844.1143859},
file = {:Users/storopoli/Documents/Mendeley Desktop/blei2006.pdf:pdf},
isbn = {1595933832},
pages = {113--120},
publisher = {ACM Press},
title = {{Dynamic topic models}},
url = {http://portal.acm.org/citation.cfm?doid=1143844.1143859},
year = {2006}
}
@incollection{Wallach2006,
address = {New York, New York, USA},
author = {Wallach, Hanna M. and M., Hanna},
booktitle = {Proceedings of the 23rd international conference on Machine learning - ICML '06},
doi = {10.1145/1143844.1143967},
file = {:Users/storopoli/Documents/Mendeley Desktop/wallach2006.pdf:pdf},
isbn = {1595933832},
pages = {977--984},
publisher = {ACM Press},
title = {{Topic modeling}},
url = {http://portal.acm.org/citation.cfm?doid=1143844.1143967},
year = {2006}
}
@article{Mohr2002,
abstract = {The recent cultural turn in American sociology has inspired a number of more scientifically oriented scholars to study the meanings that are embedded within institutions, practices, and cultural artifacts. I focus here on research that (a) emphasizes institutional (rather than individual) meanings, (b) uses a structural approach to interpretation, and (c) employs formal algorithms or quantitative procedures for reducing the complexity of meanings to simpler structural principles. I discuss two core methodological issues - the assessment of similarities and differences between items in a cultural system and the process by which structure-preserving simplifications are found in the data. I also highlight the importance of two-mode analytic procedures and I review some of the perceived benefits and criticisms of this style of research.},
author = {Mohr, John W.},
doi = {10.1146/annurev.soc.24.1.345},
file = {:Users/storopoli/Documents/Mendeley Desktop/annurev.soc.24.1.345.pdf:pdf},
issn = {0360-0572},
journal = {Annual Review of Sociology},
keywords = {culture,institutions,meaning,network,structuralism},
month = {aug},
number = {1},
pages = {345--370},
publisher = {Annual Reviews 4139 El Camino Way, P.O. Box 10139, Palo Alto, CA 94303-0139, USA},
title = {{Measuring Meaning Structures}},
url = {http://www.annualreviews.org/doi/10.1146/annurev.soc.24.1.345},
volume = {24},
year = {2002}
}
@article{Hannigan2019,
abstract = {Increasingly, management researchers are using topic modeling, a new method borrowed from computer science, to reveal phenomenon-based constructs and grounded conceptual relationships in textual data. By conceptualizing topic modeling as the process of rendering constructs and conceptual relationships from textual data, we demonstrate how this new method can advance management scholarship without turning topic modeling into a black box of complex computer-driven algorithms. We begin by comparing features of topic modeling to related techniques (content analysis, grounded theorizing, and natural language processing). We then walk through the steps of rendering with topic modeling and apply rendering to management articles that draw on topic modeling. Doing so enables us to identify and discuss how topic modeling has advanced management theory in five areas: detecting novelty and emergence, developing inductive classification systems, understanding online audiences and products, analyzing frames and social movements, and understanding cultural dynamics. We conclude with a review of new topic modeling trends and revisit the role of researcher interpretation in a world of computer-driven textual analysis.},
author = {Hannigan, Timothy and Haans, Richard Franciscus Johannes and Vakili, Keyvan and Tchalian, Hovig and Glaser, Vern and Wang, Milo and Kaplan, Sarah and Jennings, P. Devereaux},
doi = {10.5465/annals.2017.0099},
file = {:Users/storopoli/Documents/Mendeley Desktop/annals.2017.0099.pdf:pdf},
issn = {1941-6520},
journal = {Academy of Management Annals},
keywords = {COGNITION,INFORMATION PROCESSING,ORGANIZATION,RESEARCH METHODS,culture},
month = {may},
title = {{Topic modeling in management research: Rendering new theory from textual data}},
url = {http://journals.aom.org/doi/10.5465/annals.2017.0099},
year = {2019}
}
