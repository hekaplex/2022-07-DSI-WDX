{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7c102692-5b43-4f97-8394-f36ed52dbb23",
    "_uuid": "9fa43627b6ebc212b8d2aebae60ef6ef16fcc76a"
   },
   "source": [
    "<h2 style=\"margin-bottom: 18px\">Index</h2>\n",
    "\n",
    "* Imbalanced datasets\n",
    "* The metric trap\n",
    "* Confusion matrix\n",
    "* Resampling\n",
    "* Random under-sampling\n",
    "* Random over-sampling\n",
    "* Python imbalanced-learn module\n",
    "* Random under-sampling and over-sampling with imbalanced-learn\n",
    "* Under-sampling: Tomek links\n",
    "* Under-sampling: Cluster Centroids\n",
    "* Over-sampling: SMOTE\n",
    "* Over-sampling followed by under-sampling\n",
    "* Recommended reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e38ddf38-d027-4eae-95c8-749f8f40db43",
    "_uuid": "1e287038acf96fc6d6825e77ba97b03f0824be0a"
   },
   "source": [
    "<h2 id=\"t1\" style=\"margin-bottom: 18px\">Imbalanced datasets</h2>\n",
    "\n",
    "In this kernel we will know some techniques to handle highly unbalanced datasets, with a focus on resampling. The Porto Seguro's Safe Driver Prediction competition, used in this kernel, is a classic problem of unbalanced classes, since insurance claims can be considered unusual cases when considering all clients. Other classic examples of unbalanced classes are the detection of financial fraud and attacks on computer networks.\n",
    "\n",
    "Let's see how unbalanced the dataset is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: requests in c:\\users\\andre\\anaconda3\\lib\\site-packages (from kaggle) (2.27.1)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\andre\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\andre\\anaconda3\\lib\\site-packages (from kaggle) (2021.10.8)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from kaggle) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\andre\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\andre\\anaconda3\\lib\\site-packages (from kaggle) (4.62.3)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.4)\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.5.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\andre\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\andre\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\andre\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for google-pasta: [Errno 2] No such file or directory: 'c:\\\\users\\\\andre\\\\anaconda3\\\\lib\\\\site-packages\\\\google_pasta-0.2.0.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\andre\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\andre\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\andre\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\andre\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'c:\\REDO_2022_03_DSI_WD\\2022_03_DSI_WD\\drew.minkin@divergence.one\\py\\Machine Learning\\ML from Class\\14 Sampling, Validation and Transparency\\kaggle': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! python kaggle kernels output rafjaa/resampling-strategies-for-imbalanced-datasets -p /input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "3b84706a-1eb0-435f-b1ff-3f1732cc3ae4",
    "_uuid": "63eb4f34b9a7d5106da4fe6c1c871bb0025c1ae4",
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_48628\\3725319872.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtarget_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsiwd202201\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsiwd202201\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsiwd202201\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsiwd202201\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsiwd202201\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsiwd202201\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsiwd202201\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsiwd202201\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/train.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv('../input/train.csv')\n",
    "\n",
    "target_count = df_train.target.value_counts()\n",
    "print('Class 0:', target_count[0])\n",
    "print('Class 1:', target_count[1])\n",
    "print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
    "\n",
    "target_count.plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c91f9c5d-05d2-478e-9dfb-1cb848bc0fe4",
    "_uuid": "8683656d1bfdef6b5c0c623597dcbc4160a0edc1"
   },
   "source": [
    "<h2 id=\"t2\" style=\"margin-bottom: 18px\">The metric trap</h2>\n",
    "\n",
    "One of the major issues that novice users fall into when dealing with unbalanced datasets relates to the metrics used to evaluate their model. Using simpler metrics like <code>accuracy_score</code> can be misleading. In a dataset with highly unbalanced classes, if the classifier always \"predicts\" the most common class without performing any analysis of the features, it will still have a high accuracy rate, obviously illusory.\n",
    "\n",
    "Let's do this experiment, using simple cross-validation and no feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0efbfb8a-76ab-4a86-b093-25271dcfcc06",
    "_uuid": "6d33cfa94ebb019b7c3065ea5f5dbe99ae52aeb1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Remove 'id' and 'target' columns\n",
    "labels = df_train.columns[2:]\n",
    "\n",
    "X = df_train[labels]\n",
    "y = df_train['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c46b98a7-d500-4911-a7b5-c8fc8fbed069",
    "_uuid": "5b17ee8d3629cc346398e63269205e5b654cef80"
   },
   "source": [
    "Now let's run the same code, but using only one feature (which should drastically reduce the accuracy of the classifier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bd97a34a-8e27-4eb2-a552-fe21f860dd15",
    "_uuid": "5c7c4e3f364c664f52d04d24f948cc416d2d7e4c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train[['ps_calc_01']], y_train)\n",
    "y_pred = model.predict(X_test[['ps_calc_01']])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "68d4ffaf-4412-4ff3-a9cd-38bea195da3b",
    "_uuid": "d9d8b57f458bdd107ae08b76b0008d80e0674d97"
   },
   "source": [
    "As we can see, the high accuracy rate was just an illusion. In this way, the choice of the metric used in unbalanced datasets is extremely important. In this competition, the evaluation metric is the Normalized Gini Coefficient, a more robust metric for imbalanced datasets, that ranges from approximately 0 for random guessing, to approximately 0.5 for a perfect score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e53e9f0f-8888-4fd9-b0d8-3bc937448162",
    "_uuid": "a176bd80315afd0f7c21fd26ab1841867a5eb7d0"
   },
   "source": [
    "<h2 id=\"t3\" style=\"margin-bottom: 18px\">Confusion matrix</h2>\n",
    "\n",
    "An interesting way to evaluate the results is by means of a confusion matrix, which shows the correct and incorrect predictions for each class. In the first row, the first column indicates how many classes 0 were predicted correctly, and the second column, how many classes 0 were predicted as 1. In the second row, we note that all class 1 entries were erroneously predicted as class 0.\n",
    "\n",
    "Therefore, the higher the diagonal values of the confusion matrix the better, indicating many correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "394daa2b-700c-45fc-99d7-db08245a7697",
    "_uuid": "39c3256de9817f64c9ae47de5f1f78531d373015",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['Class 0', 'Class 1']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b27346eb-7bf3-4360-993a-fb91e62bb937",
    "_uuid": "875f5ab3b5afcdaf3c7754ce957cb01fd32bf65c"
   },
   "source": [
    "<h2 id=\"t4\" style=\"margin-bottom: 18px\">Resampling</h2>\n",
    "\n",
    "A widely adopted technique for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and / or adding more examples from the minority class (over-sampling)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "03d31a16-7b66-4096-88d7-d548db734390",
    "_uuid": "2232ac0fb192a468486b400846f88913a36957e6"
   },
   "source": [
    "![](https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/resampling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0df1a3f3-49ff-4ada-80f1-198bbbd79525",
    "_uuid": "67e203e0919c818e871650ef194fe497df2d39b5"
   },
   "source": [
    "Despite the advantage of balancing classes, these techniques also have their weaknesses (there is no free lunch). The simplest implementation of over-sampling is to duplicate random records from the minority class, which can cause overfitting. In under-sampling, the simplest technique involves removing random records from the majority class, which can cause loss of information.\n",
    "\n",
    "Let's implement a basic example, which uses the <code>DataFrame.sample</code> method to get random samples each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2adbc1c9-8cdf-43d9-9a57-f24f503ba523",
    "_uuid": "f959c30be59ad1eccaed33f48a35d99be053b547",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = df_train.target.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = df_train[df_train['target'] == 0]\n",
    "df_class_1 = df_train[df_train['target'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "152ea73a-aa23-4fd2-a3f5-1f55c69041ae",
    "_uuid": "b765be76a182930feb650b01dd4d1de90501bbce"
   },
   "source": [
    "<h2 id=\"t5\">Random under-sampling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a0e61bc8-cef1-4828-9c5f-49c1c50c522c",
    "_uuid": "2a667d73560fb6408897835809a9d67310b45323",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GIVES US SAME # OF 0'S AS WE HAVE 1'S\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.target.value_counts())\n",
    "\n",
    "df_test_under.target.value_counts().plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "be656d47-e529-4533-b975-cf6de072d959",
    "_uuid": "17192fe8557463941e3abd4633b58ced0037721b"
   },
   "source": [
    "<h2 id=\"t6\">Random over-sampling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8ca1ac09-5d61-4cf7-99a4-e299f4955c97",
    "_uuid": "431942c08c59f0a6ae629c3c38485bf85d001892",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.target.value_counts())\n",
    "\n",
    "df_test_over.target.value_counts().plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9fd90ddc-f2fc-487d-b177-0c540daf2eff",
    "_uuid": "9672899d4029b71b72897927ce464d6d7427ce77"
   },
   "source": [
    "<h2 id=\"t7\" style=\"margin-bottom: 18px\">Python imbalanced-learn module</h2>\n",
    "\n",
    "A number of more sophisticated resapling techniques have been proposed in the scientific literature.\n",
    "\n",
    "For example, we can cluster the records of the majority class, and do the under-sampling by removing records from each cluster, thus seeking to preserve information. In over-sampling, instead of creating exact copies of the minority class records, we can introduce small variations into those copies, creating more diverse synthetic samples.\n",
    "\n",
    "Let's apply some of these resampling techniques, using the Python library [imbalanced-learn](http://contrib.scikit-learn.org/imbalanced-learn/stable/). It is compatible with scikit-learn and is part of scikit-learn-contrib projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fdf3f76d-aacb-4ccc-9649-736dce7a237c",
    "_uuid": "41b482ec89f13dd22e85612404300041a3e71deb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5542beb4-6aee-401a-8bc0-2a522fbbe90b",
    "_uuid": "ff93d1707c416178c010c125319220b785dca984"
   },
   "source": [
    "For ease of visualization, let's create a small unbalanced sample dataset using the <code>make_classification</code> method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e97abde1-c324-47b5-a33c-3b8b92268b5e",
    "_uuid": "3126327b6f4b4c469701ac7a76590f5e55e17076",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_classes=2, class_sep=1.5, weights=[0.9, 0.1],\n",
    "    n_informative=3, n_redundant=1, flip_y=0,\n",
    "    n_features=20, n_clusters_per_class=1,\n",
    "    n_samples=100, random_state=10\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df['target'] = y\n",
    "df.target.value_counts().plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4de57657-3aed-4444-a609-318063391763",
    "_uuid": "d348b114ec1594eeefa0a67aab8b54e5b9ee2bdf"
   },
   "source": [
    "We will also create a 2-dimensional plot function, <code>plot_2d_space</code>, to see the data distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8003c84c-fee4-45c7-b490-90a185799760",
    "_uuid": "b2a02a4ff687fb099232a0468917ec8ab737d22d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_2d_space(X, y, label='Classes'):   \n",
    "    colors = ['#1F77B4', '#FF7F0E']\n",
    "    markers = ['o', 's']\n",
    "    for l, c, m in zip(np.unique(y), colors, markers):\n",
    "        plt.scatter(\n",
    "            X[y==l, 0],\n",
    "            X[y==l, 1],\n",
    "            c=c, label=l, marker=m\n",
    "        )\n",
    "    plt.title(label)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2c565bbc-39ed-45a2-8b3d-bc501e2510aa",
    "_uuid": "aabc110dd8d1b36345df6aada1c59b864e48e8e6"
   },
   "source": [
    "Because the dataset has many dimensions (features) and our graphs will be 2D, we will reduce the size of the dataset using Principal Component Analysis (PCA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "22b689c8-b296-4736-9aa6-46f36283f91f",
    "_uuid": "f64eff19d1304d4bd1e92d2c51a8a953cd17d7f9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "plot_2d_space(X, y, 'Imbalanced dataset (2 PCA components)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c3c9a24f-3cd0-4c8d-8a4d-4403c4f1a641",
    "_uuid": "0d7316b04837aa103003d667f63ecb05d43fc04e"
   },
   "source": [
    "<h2 id=\"#t72\">Random under-sampling and over-sampling with imbalanced-learn</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "28bdbe23-5eeb-4335-8c70-7a00bbac3e03",
    "_uuid": "8a56a4b118d7cae885e4c6a45fa02b2f066ece78",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(return_indices=True)\n",
    "X_rus, y_rus, id_rus = rus.fit_sample(X, y)\n",
    "\n",
    "print('Removed indexes:', id_rus)\n",
    "\n",
    "plot_2d_space(X_rus, y_rus, 'Random under-sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c8eaed30-339e-4d23-a0f2-fbd687b217ea",
    "_uuid": "be5b90300f0a25bbe7d1822503e7fc5185a906b2",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_sample(X, y)\n",
    "\n",
    "print(X_ros.shape[0] - X.shape[0], 'new random picked points')\n",
    "\n",
    "plot_2d_space(X_ros, y_ros, 'Random over-sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3156134f-539b-48b8-b9d0-64095fe50c1c",
    "_uuid": "b3f9ac47a157d9096a626360408859b795299c24"
   },
   "source": [
    "<h2 id=\"t8\" style=\"margin-bottom: 18px\">Under-sampling: Tomek links</h2>\n",
    "\n",
    "Tomek links are pairs of very close instances, but of opposite classes. Removing the instances of the majority class of each pair increases the space between the two classes, facilitating the classification process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f131f7e0-007d-406e-9e1c-db352d2d8433",
    "_uuid": "85c01c0e6baa1b984585c1db34c5ab0315cbf8ff"
   },
   "source": [
    "![](https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/tomek.png?v=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "45bf057b-369c-4f37-a5ac-7417ad79253d",
    "_uuid": "733a86ccfaaabf701fb2d1f9997c732b19630df3"
   },
   "source": [
    "In the code below, we'll use <code>ratio='majority'</code> to resample the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "58f13562-c0c6-4247-bf40-c6dec764ff3a",
    "_uuid": "0c93b1e11359f4d1eb873280b61aa0f54ee8bd36",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks(return_indices=True, ratio='majority')\n",
    "X_tl, y_tl, id_tl = tl.fit_sample(X, y)\n",
    "\n",
    "print('Removed indexes:', id_tl)\n",
    "\n",
    "plot_2d_space(X_tl, y_tl, 'Tomek links under-sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fef831bd-ecec-429c-aef2-5d51d1188820",
    "_uuid": "b4e75fffe4c91afcd63705aa7bcb16b6fd9f6b1f"
   },
   "source": [
    "<h2 id=\"t9\" style=\"margin-bottom: 18px\">Under-sampling: Cluster Centroids</h2>\n",
    "\n",
    "This technique performs under-sampling by generating centroids based on clustering methods. The data will be previously grouped by similarity, in order to preserve information.\n",
    "\n",
    "In this example we will pass the <code>{0: 10}</code> dict for the parameter <code>ratio</code>, to preserve 10 elements from the majority class (0), and all minority class (1) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "91001b3e-fe5c-4dc1-8501-395e1218cba1",
    "_uuid": "ad088a08f4f9e0b646571950928c7fff47f52f98",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids(ratio={0: 10})\n",
    "X_cc, y_cc = cc.fit_sample(X, y)\n",
    "\n",
    "plot_2d_space(X_cc, y_cc, 'Cluster Centroids under-sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "78adb7b4-a7e1-4d10-9cc2-6bf6477c63df",
    "_uuid": "b3741f5c14acdbd76e25725e2d73df5f2cb0a239"
   },
   "source": [
    "<h2 id=\"t10\" style=\"margin-bottom: 18px\">Over-sampling: SMOTE</h2>\n",
    "\n",
    "SMOTE (Synthetic Minority Oversampling TEchnique) consists of synthesizing elements for the minority class, based on those that already exist. It works randomly picingk a point from the minority class and computing the k-nearest neighbors for this point. The synthetic points are added between the chosen point and its neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5162646f-da82-4877-b6d8-25a8be7f42e9",
    "_uuid": "51697e21b7cdb4064dda18aa24e6ecf039b1132b"
   },
   "source": [
    " ![](https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/smote.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9c0a0d78-8427-437e-aa24-ffe2bd12edb2",
    "_uuid": "9393851db694c178faf93615bf05addedf5d678b"
   },
   "source": [
    "We'll use <code>ratio='minority'</code> to resample the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "97e9f84e-0951-4037-b882-57545f9d967a",
    "_uuid": "74457c951aabf5b16be1c4282c15d9cb2034f26b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(ratio='minority')\n",
    "X_sm, y_sm = smote.fit_sample(X, y)\n",
    "\n",
    "plot_2d_space(X_sm, y_sm, 'SMOTE over-sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "20c3cdbb-a7c1-45a5-8dd9-84cff7d9af31",
    "_uuid": "d7ebbeb741ad6469cb7ebbced3499acd3c49856a"
   },
   "source": [
    "<h2 id=\"t11\" style=\"margin-bottom: 18px\">Over-sampling followed by under-sampling</h2>\n",
    "\n",
    "Now, we will do a combination of over-sampling and under-sampling, using the SMOTE and Tomek links techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ab732fe1-45c1-4163-b70e-7a2ce2dbe42f",
    "_uuid": "b740fbaf8677522d3b3040e2f47e3b954dc56877",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(ratio='auto')\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "plot_2d_space(X_smt, y_smt, 'SMOTE + Tomek links')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "28d4431f-bc32-4cf0-988e-9df412cc22c1",
    "_uuid": "401bcb8e508e584feca3a34ecfb9de270fde951c"
   },
   "source": [
    "<h2 id=\"t12\" style=\"margin-bottom: 18px\">Recommended reading</h2>\n",
    "\n",
    "The imbalanced-learn documentation:<br>\n",
    "http://contrib.scikit-learn.org/imbalanced-learn/stable/index.html\n",
    "\n",
    "The imbalanced-learn GitHub:<br>\n",
    "https://github.com/scikit-learn-contrib/imbalanced-learn\n",
    "\n",
    "Comparison of the combination of over- and under-sampling algorithms:<br>\n",
    "http://contrib.scikit-learn.org/imbalanced-learn/stable/auto_examples/combine/plot_comparison_combine.html\n",
    "\n",
    "Chawla, Nitesh V., et al. \"SMOTE: synthetic minority over-sampling technique.\" Journal of artificial intelligence research 16 (2002):<br>\n",
    "https://www.jair.org/media/953/live-953-2037-jair.pdf"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4f92193806e2908606a5f23edd55a5282f2f433b73b1c504507f9256ed9f0b4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
